{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer (ViT) Implementation Using Pytorch\n",
    "\n",
    "This notebook demonstrates the implementation of a Vision Transformer (ViT) from scratch using PyTorch. The Vision Transformer is a model for image classification that leverages the Transformer architecture, which has been highly successful in natural language processing tasks.\n",
    "\n",
    "We will be using the CIFAR-10 dataset for training and evaluating our model. The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 different classes, with 6,000 images per class. The dataset is divided into 50,000 training images and 10,000 test images.\n",
    "\n",
    "The implementation includes the following components:\n",
    "- **Patcher**: Divides the input image into smaller patches.\n",
    "- **LinearProjectionFlatten**: Projects the patches into a higher-dimensional space.\n",
    "- **PositionalEncoder**: Adds positional information to the patches.\n",
    "- **SelfAttention**: Implements the self-attention mechanism.\n",
    "- **AttentionBlock**: Combines self-attention with linear projections.\n",
    "- **TransformerEncoder**: Stacks multiple attention blocks with normalization and feed-forward layers.\n",
    "- **MLPHead**: A simple feed-forward network for final classification.\n",
    "- **VisionTransformer**: Combines all components to form the complete Vision Transformer model.\n",
    "\n",
    "The model is trained on the CIFAR-10 dataset for 10 epochs using the Adam optimizer and cross-entropy loss. The training loss is plotted to visualize the training process, and the model's prediction for a sample image is compared with the true label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data (Cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple transform for data since real focus is on ViT\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# One-hot encoding the target labels\n",
    "def one_hot_encode(label):\n",
    "    return F.one_hot(torch.tensor(label), num_classes=10).float()\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root='../../../datasets',\n",
    "    train=True,\n",
    "    download=False, # Download the dataset if it does not exist\n",
    "    transform=transform,\n",
    "    target_transform=one_hot_encode\n",
    ")\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root='../../../datasets',\n",
    "    train=False,\n",
    "    download=False, # Download the dataset if it does not exist\n",
    "    transform=transform,\n",
    "    target_transform=one_hot_encode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will implement the Vision Transformer (ViT) architecture as described in its original paper: [\"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\"](https://arxiv.org/abs/2010.11929).\n",
    "\n",
    "![Vision Transformer](ViT_image_paper.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patcher\n",
    "\n",
    "The `Patcher` class is responsible for dividing the input image into smaller patches. Each patch is then flattened into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patcher(nn.Module):\n",
    "    def __init__(self, patch_size=16, embed_dim=512):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        # Batch size, Num patches, Flatten features\n",
    "        patches = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearProjectionFlatten\n",
    "\n",
    "The `LinearProjectionFlatten` class takes the patches created by the `Patcher` and projects them into a higher-dimensional space using a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProjectionFlatten(nn.Module):\n",
    "    def __init__(self, patcher: Patcher, num_channels=3):\n",
    "        super().__init__()\n",
    "        self.patcher: Patcher = patcher\n",
    "        self.patch_embedding = nn.Linear(num_channels * patcher.patch_size ** 2, patcher.embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        patches = self.patcher(x)\n",
    "        embedded_patches = self.patch_embedding(patches)\n",
    "        return embedded_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PositionalEncoder\n",
    "\n",
    "The `PositionalEncoder` class adds positional information to the patches, which helps the model understand the order of the patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=512, seq_len=5000):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        position = torch.arange(0, seq_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * -(np.log(10000.0) / embed_dim))\n",
    "\n",
    "        pe = torch.zeros(seq_len, embed_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Using buffer to tell pytorch this is not learnable\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        x = x + self.pe[:seq_len, :].unsqueeze(dim=0)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelfAttention\n",
    "\n",
    "The `SelfAttention` class implements the self-attention mechanism, which allows the model to focus on different parts of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def calculate_QKT(self, queries: Tensor, keys: Tensor):\n",
    "        return torch.bmm(queries, keys.transpose(1, 2)) / np.sqrt(queries.shape[-1])\n",
    " \n",
    "    def forward(self, queries: Tensor, keys: Tensor, values: Tensor, \n",
    "                batch_size: int, seq_len: int, embed_dim: int, n_head: int):\n",
    "        \n",
    "        keys = keys.transpose(1, 2).contiguous().view(batch_size * n_head, seq_len, embed_dim)\n",
    "        queries = queries.transpose(1, 2).contiguous().view(batch_size * n_head, seq_len, embed_dim)\n",
    "        values = values.transpose(1, 2).contiguous().view(batch_size * n_head, seq_len, embed_dim)\n",
    "\n",
    "        QKT = self.calculate_QKT(queries, keys)\n",
    "        scores = F.softmax(QKT, dim=2)\n",
    "        attention: Tensor = torch.bmm(scores, values).view(batch_size, n_head, seq_len, embed_dim)\n",
    "        attention = attention.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim * n_head)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AttentionBlock\n",
    "\n",
    "The `AttentionBlock` class combines the self-attention mechanism with linear projections to form a complete attention block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim=512, n_head=8):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_head = n_head\n",
    "\n",
    "        # W for queries\n",
    "        self.Wq = nn.Linear(embed_dim, embed_dim * n_head, bias=False)\n",
    "        # W for keys\n",
    "        self.Wk = nn.Linear(embed_dim, embed_dim * n_head, bias=False)\n",
    "        # W for values\n",
    "        self.Wv = nn.Linear(embed_dim, embed_dim * n_head, bias=False)\n",
    "        # W for final results\n",
    "        self.Wr = nn.Linear(embed_dim * n_head, embed_dim)\n",
    "\n",
    "        self.attention = SelfAttention()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        n_head = self.n_head\n",
    "        batch_size, seq_len, embed_dim = x.size()\n",
    "\n",
    "        queries = self.Wq(x).view(batch_size, seq_len, n_head, embed_dim)\n",
    "        keys = self.Wk(x).view(batch_size, seq_len, n_head, embed_dim)\n",
    "        values = self.Wv(x).view(batch_size, seq_len, n_head, embed_dim)\n",
    "\n",
    "        result = self.attention(queries, keys, values, batch_size,\n",
    "                                seq_len, embed_dim, n_head)\n",
    "        \n",
    "        return self.Wr(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransformerEncoder\n",
    "\n",
    "The `TransformerEncoder` class stacks multiple attention blocks and adds normalization and feed-forward layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=512, n_head=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = AttentionBlock(embed_dim, n_head)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        hidden_size = embed_dim * 2\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        sc = self.attention(x) # First skip connection\n",
    "        x = self.norm1(x + sc)\n",
    "        sc = self.mlp(x)\n",
    "        out = self.norm2(x + sc) # Second skip connection\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPHead\n",
    "\n",
    "The `MLPHead` class is a simple feed-forward network that produces the final classification logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, n_classes, embed_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(embed_dim, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x_pool = x.mean(dim=1)\n",
    "        \n",
    "        logits = self.layers(x_pool)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VisionTransformer\n",
    "\n",
    "The `VisionTransformer` class combines all the components to form the complete Vision Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, n_classes, patch_size=16, seq_len=5000, n_head=8, embed_dim=512, num_channels=3, n_transformers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        patcher = Patcher(patch_size, embed_dim)\n",
    "        self.linear_flatter = LinearProjectionFlatten(patcher, num_channels)\n",
    "\n",
    "        self.positional_encoding = PositionalEncoder(embed_dim, seq_len)\n",
    "\n",
    "        transformer_encoders = [TransformerEncoder(embed_dim, n_head) for _ in range(n_transformers)]\n",
    "        self.transformers = nn.Sequential(*transformer_encoders)\n",
    "\n",
    "        self.mlp_head = MLPHead(n_classes, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        flatten = self.linear_flatter(x)\n",
    "        \n",
    "        positional_encoded = self.positional_encoding(flatten)\n",
    "\n",
    "        transform = self.transformers(positional_encoded)\n",
    "        return self.mlp_head(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "The model is trained on the CIFAR-10 dataset for 10 epochs using the Adam optimizer and cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:31<04:46, 31.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.0687, Test Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:59<03:56, 29.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.7198, Test Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:29<03:27, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.5209, Test Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:00<03:01, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.3976, Test Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:33<02:35, 31.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 1.3147, Test Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:05<02:05, 31.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 1.2472, Test Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [03:38<01:36, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 1.1756, Test Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [04:22<01:11, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.1297, Test Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [04:59<00:35, 36.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 1.0865, Test Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:33<00:00, 33.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 1.0327, Test Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = VisionTransformer(n_classes=10, patch_size=4, seq_len=5000, n_head=8,\n",
    "                        embed_dim=50, num_channels=3, n_transformers=6).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  \n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    epoch_loss_train = 0\n",
    "    model.train()\n",
    "\n",
    "    for img, label in train_dataloader:\n",
    "        img: Tensor = img.to(device)\n",
    "        label: Tensor = label.to(device)\n",
    "\n",
    "        logits: Tensor = model(img)\n",
    "        loss: Tensor = loss_fn(logits, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss_train += loss.item()\n",
    "\n",
    "    # Using test dataset as validation dataset\n",
    "    epoch_loss_test = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_dataloader:\n",
    "            img: Tensor = img.to(device)\n",
    "            label: Tensor = label.to(device)\n",
    "\n",
    "            logits: Tensor = model(img)\n",
    "            loss: Tensor = loss_fn(logits, label)\n",
    "\n",
    "            epoch_loss_test = loss.item()\n",
    "\n",
    "    epoch_loss_train /= num_batches\n",
    "    epoch_loss_test /= num_batches\n",
    "    train_losses.append(epoch_loss_train)\n",
    "    test_losses.append(epoch_loss_test)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss_train:.4f}, Test Loss: {epoch_loss_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEV0lEQVR4nO3deVxWZf7/8fcNyCabGiIqioqhuOCuqJWNmqljaTWWWe71a9LJZWrKMctW0r6WNplmjTo1ZZamNZYVmVruKyrmniajgksKioYK5/fHGW68ZREQOHB4PR+P8+Dm3Gf5HFzuN9e5znU5DMMwBAAAYBNuVhcAAABQnAg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AMqUb775Ri1atJC3t7ccDofOnj1rdUmWmTRpkhwOh06dOmV1KUC5QrgBKoB58+bJ4XBo8+bNVpeSr9OnT6t///7y8fHRjBkz9OGHH6py5cpWlwWgnPGwugAAyLJp0yadO3dOL730krp162Z1OQDKKVpuAJQZJ06ckCQFBQUV2zHT0tKK7VgAygfCDQCnbdu2qWfPngoICJCfn5+6du2q9evXu2xz+fJlvfDCC2rYsKG8vb1VrVo1de7cWXFxcc5tkpKSNHToUNWuXVteXl4KDQ3V3XffrcOHD+d57i5dumjw4MGSpLZt28rhcGjIkCHO9z/77DO1bt1aPj4+uummm/TQQw/p6NGjLscYMmSI/Pz8dPDgQfXq1Uv+/v4aOHBgvtd89OhRDRs2TCEhIfLy8lKTJk00Z84cl21Wrlwph8OhBQsW6O9//7tq1KihypUr66677lJiYmKOYxakVknas2eP+vfvr+DgYPn4+CgyMlITJkzIsd3Zs2c1ZMgQBQUFKTAwUEOHDtWFCxfyvS6gIuO2FABJ0q5du3TLLbcoICBAf/vb31SpUiW9++676tKli1atWqX27dtLMju5xsbGasSIEWrXrp1SU1O1efNmbd26Vd27d5ck3Xvvvdq1a5f+8pe/KDw8XCdOnFBcXJyOHDmi8PDwXM8/YcIERUZGavbs2XrxxRdVr149NWjQQJLZZ2jo0KFq27atYmNjlZycrOnTp2vNmjXatm2bS0vPlStX1KNHD3Xu3Fn/93//J19f3zyvOTk5WR06dJDD4dCoUaMUHBysZcuWafjw4UpNTdWYMWNctn/llVfkcDj09NNP68SJE5o2bZq6deum+Ph4+fj4FKrWHTt26JZbblGlSpX06KOPKjw8XAcPHtR//vMfvfLKKy7n7d+/v+rVq6fY2Fht3bpV77//vqpXr67JkycX9I8XqFgMALY3d+5cQ5KxadOmPLfp27ev4enpaRw8eNC57tixY4a/v79x6623OtdFR0cbvXv3zvM4Z86cMSQZr7/+erHUeenSJaN69epG06ZNjYsXLzrXL1261JBkPPfcc851gwcPNiQZzzzzTIHON3z4cCM0NNQ4deqUy/oHHnjACAwMNC5cuGAYhmGsWLHCkGTUqlXLSE1NdW736aefGpKM6dOnF7rWW2+91fD39zd+/fVXl3NnZmY6Xz///POGJGPYsGEu2/Tr18+oVq1aga4RqIi4LQVAGRkZ+u6779S3b1/Vr1/fuT40NFQPPvigVq9erdTUVElmf5hdu3Zp//79uR7Lx8dHnp6eWrlypc6cOXPDtW3evFknTpzQ448/Lm9vb+f63r17q1GjRvrqq69y7PPnP//5usc1DEOLFi1Snz59ZBiGTp065Vx69OihlJQUbd261WWfQYMGyd/f3/n9fffdp9DQUH399deFqvXkyZP68ccfNWzYMNWpU8flHA6HI0etjz32mMv3t9xyi06fPu38MwHginADQCdPntSFCxcUGRmZ473GjRsrMzPT2bfkxRdf1NmzZ3XzzTerWbNmeuqpp7Rjxw7n9l5eXpo8ebKWLVumkJAQ3XrrrZoyZYqSkpKKVNuvv/4qSbnW1qhRI+f7WTw8PFS7du3rHvfkyZM6e/asZs+ereDgYJdl6NChkrI7OGdp2LChy/cOh0MRERHOvkQFrfWXX36RJDVt2vS6dUrKEYCqVKkiScUSHgE7ItwAKJRbb71VBw8e1Jw5c9S0aVO9//77atWqld5//33nNmPGjNG+ffsUGxsrb29vTZw4UY0bN9a2bdtKvD4vLy+5uV3/v7bMzExJ0kMPPaS4uLhcl06dOpV0uQXi7u6e63rDMEq5EqB8INwAUHBwsHx9fbV3794c7+3Zs0dubm4KCwtzrqtataqGDh2q+fPnKzExUc2bN9ekSZNc9mvQoIH++te/6rvvvlNCQoIuXbqkqVOnFrq2unXrSlKute3du9f5fmEFBwfL399fGRkZ6tatW65L9erVXfa59lacYRg6cOCAs5N0QWvNuvWXkJBQpNoB5I9wA0Du7u6644479MUXX7g8rp2cnKyPP/5YnTt3VkBAgCRzFOGr+fn5KSIiQunp6ZKkCxcu6Pfff3fZpkGDBvL393duUxht2rRR9erVNWvWLJf9ly1bpt27d6t3796FPqZkXvO9996rRYsW5RoyTp48mWPdBx98oHPnzjm/X7hwoY4fP66ePXsWqtbg4GDdeuutmjNnjo4cOeJyDlpjgBvHo+BABTJnzhx98803OdaPHj1aL7/8suLi4tS5c2c9/vjj8vDw0Lvvvqv09HRNmTLFuW1UVJS6dOmi1q1bq2rVqtq8ebMWLlyoUaNGSZL27dunrl27qn///oqKipKHh4cWL16s5ORkPfDAA4WuuVKlSpo8ebKGDh2q2267TQMGDHA+Xh0eHq6xY8cW+efx2muvacWKFWrfvr0eeeQRRUVF6bffftPWrVv1/fff67fffnPZvmrVqurcubOGDh2q5ORkTZs2TREREXrkkUcKXetbb72lzp07q1WrVnr00UdVr149HT58WF999ZXi4+OLfE0AxKPgQEWQ9Yh1XktiYqJhGIaxdetWo0ePHoafn5/h6+tr3H777cbatWtdjvXyyy8b7dq1M4KCggwfHx+jUaNGxiuvvGJcunTJMAzDOHXqlDFy5EijUaNGRuXKlY3AwECjffv2xqefflrgOnN7ZH3BggVGy5YtDS8vL6Nq1arGwIEDjf/+978u2wwePNioXLlyoX42ycnJxsiRI42wsDCjUqVKRo0aNYyuXbsas2fPdm6T9Sj4/PnzjfHjxxvVq1c3fHx8jN69e+d4lLugtRqGYSQkJBj9+vUzgoKCDG9vbyMyMtKYOHGi8/2sR8FPnjyZ68/p0KFDhbpWoKJwGAZtoACQn5UrV+r222/XZ599pvvuu8/qcgBcB31uAACArRBuAACArRBuAACArdDnBgAA2AotNwAAwFYINwAAwFYq3CB+mZmZOnbsmPz9/XOdfRcAAJQ9hmHo3Llzqlmz5nXnj6tw4ebYsWMuc+QAAIDyIzExUbVr1853mwoXbvz9/SWZP5ysuXIAAEDZlpqaqrCwMOfneH4qXLjJuhUVEBBAuAEAoJwpSJcSOhQDAABbIdwAAABbIdwAAABbqXB9bgAAKEkZGRm6fPmy1WWUS56entd9zLsgCDcAABQDwzCUlJSks2fPWl1KueXm5qZ69erJ09Pzho5DuAEAoBhkBZvq1avL19eXgWILKWuQ3ePHj6tOnTo39PMj3AAAcIMyMjKcwaZatWpWl1NuBQcH69ixY7py5YoqVapU5OPQoRgAgBuU1cfG19fX4krKt6zbURkZGTd0HMINAADFhFtRN6a4fn6EGwAAYCuEGwAAUCzCw8M1bdo0q8ugQzEAABVZly5d1KJFi2IJJZs2bVLlypVvvKgbRMtNMdqwQUpOtroKAACKj2EYunLlSoG2DQ4OLhOdqgk3xWTZMqlLF6l3b+n8eaurAQDg+oYMGaJVq1Zp+vTpcjgccjgcmjdvnhwOh5YtW6bWrVvLy8tLq1ev1sGDB3X33XcrJCREfn5+atu2rb7//nuX4117W8rhcOj9999Xv3795Ovrq4YNG+rLL78s8esi3BSThg0lPz9pyxbp/vulAoZcAIANGYaUlmbNYhgFr3P69OmKiYnRI488ouPHj+v48eMKCwuTJD3zzDN67bXXtHv3bjVv3lznz59Xr169tHz5cm3btk133nmn+vTpoyNHjuR7jhdeeEH9+/fXjh071KtXLw0cOFC//fbbjfx4r4s+N8UkIkJaulS6/Xbp66+lxx+X3n1X4qlAAKh4Llwwf+G1wvnzUkG7vQQGBsrT01O+vr6qUaOGJGnPnj2SpBdffFHdu3d3blu1alVFR0c7v3/ppZe0ePFiffnllxo1alSe5xgyZIgGDBggSXr11Vf11ltvaePGjbrzzjsLe2kFRstNMWrfXvrkE8nNTXrvPenVV62uCACAomnTpo3L9+fPn9eTTz6pxo0bKygoSH5+ftq9e/d1W26aN2/ufF25cmUFBAToxIkTJVJzFlpuitldd0lvv2223Dz7rFS7tjR4sNVVAQBKk6+vdf0vi6s/77VPPT355JOKi4vT//3f/ykiIkI+Pj667777dOnSpXyPc+00Cg6HQ5mZmcVTZB4INyXgz3+Wfv1VmjxZGjFCqllTuqplDwBgcw5HwW8NWc3T07NA0x2sWbNGQ4YMUb9+/SSZLTmHDx8u4eqKhttSJeTVV6UHHzQ7Ft97rxQfb3VFAADkFB4erg0bNujw4cM6depUnq0qDRs21Oeff674+Hht375dDz74YIm3wBQV4aaEuLlJc+aYHYzPnZN69ZKuc1sSAIBS9+STT8rd3V1RUVEKDg7Osw/NG2+8oSpVqqhjx47q06ePevTooVatWpVytQXjMIzCPDRWvGJjY/X5559rz5498vHxUceOHTV58mRFRkbmu99nn32miRMn6vDhw2rYsKEmT56sXr16FeicqampCgwMVEpKigICAorjMvJ19qx0yy1SQoIUFSWtXi1VqVLipwUAlKLff/9dhw4dUr169eTt7W11OeVWfj/Hwnx+W9pys2rVKo0cOVLr169XXFycLl++rDvuuENpaWl57rN27VoNGDBAw4cP17Zt29S3b1/17dtXCQkJpVh5wQUFmY+G16ol/fyz1K+flJ5udVUAANiXpS031zp58qSqV6+uVatW6dZbb811m/vvv19paWlaunSpc12HDh3UokULzZo167rnKO2Wmyw7dpgtOKmp0gMPSB99ZN66AgCUf7TcFA9btNxcKyUlRZI5UFBe1q1bp27durms69Gjh9atW5fr9unp6UpNTXVZrNC8ufT555KHhzkWzjPPWFIGAAC2V2bCTWZmpsaMGaNOnTqpadOmeW6XlJSkkJAQl3UhISFKSkrKdfvY2FgFBgY6l6xhpa3QtavZyViSXn9d+sc/LCsFAADbKjPhZuTIkUpISNAnn3xSrMcdP368UlJSnEtiYmKxHr+wHn44e+Ti0aOlxYstLQcAANspE+Fm1KhRWrp0qVasWKHatWvnu22NGjWUnJzssi45Odk5J8a1vLy8FBAQ4LJY7ZlnpMceMyc3e/BBKY87agAAoAgsDTeGYWjUqFFavHixfvjhB9WrV++6+8TExGj58uUu6+Li4hQTE1NSZRY7h8O8JfXHP0q//y716SPt22d1VQAA2IOl4WbkyJH697//rY8//lj+/v5KSkpSUlKSLl686Nxm0KBBGj9+vPP70aNH65tvvtHUqVO1Z88eTZo0SZs3b853RtKyKKtjcdu20unT0p13Stc0SAEAgCKwNNzMnDlTKSkp6tKli0JDQ53LggULnNscOXJEx48fd37fsWNHffzxx5o9e7aio6O1cOFCLVmyJN9OyGVV5crS0qVS/frSoUNmS04+Q/wAAIACKFPj3JQGq8a5yc/+/VJMjNmC07u3tGSJ2bIDACgfGOemeNhynJuKqmFDswXH21v66itp5EizszEAACWtS5cuGjNmTLEdb8iQIerbt2+xHa8oCDdlRIcO0vz5Zmfj2bOl2FirKwIAoHwi3JQhfftmD+w3YYL0wQeWlgMAsLkhQ4Zo1apVmj59uhwOhxwOhw4fPqyEhAT17NlTfn5+CgkJ0cMPP6xTp04591u4cKGaNWsmHx8fVatWTd26dVNaWpomTZqkf/3rX/riiy+cx1u5cmWpXxc9O8qYkSOlI0ekKVOk4cOl0FCpe3erqwIAFIphSBkXrDm3u695G6AApk+frn379qlp06Z68cUXJUmVKlVSu3btNGLECL355pu6ePGinn76afXv318//PCDjh8/rgEDBmjKlCnq16+fzp07p59++kmGYejJJ5/U7t27lZqaqrlz50rKf0qlkkK4KYNiY6XERPM21b33Sj/9JEVHW10VAKDAMi5In/pZc+7+5yWPygXaNDAwUJ6envL19XUOhvvyyy+rZcuWejVrOH1Jc+bMUVhYmPbt26fz58/rypUruueee1S3bl1JUrNmzZzb+vj4KD09Pc/BdUsDt6XKIDc3ae5cqUsX6dw5qVcvM+wAAFDStm/frhUrVsjPz8+5NGrUSJJ08OBBRUdHq2vXrmrWrJn+9Kc/6b333tOZM2csrtoVLTdllJeXOe9U587Srl1Sz57S6tVSUJDVlQEArsvd12xBsercN+D8+fPq06ePJk+enOO90NBQubu7Ky4uTmvXrtV3332nf/zjH5owYYI2bNhQoJkGSgPhpgwLCpK+/tocA2fXLqlfP+mbb8zgAwAowxyOAt8aspqnp6cyMjKc37dq1UqLFi1SeHi4PPIYdM3hcKhTp07q1KmTnnvuOdWtW1eLFy/WuHHjchzPCtyWKuPq1DEDjr+/tHKlNGSIlJlpdVUAALsIDw/Xhg0bdPjwYZ06dUojR47Ub7/9pgEDBmjTpk06ePCgvv32Ww0dOlQZGRnasGGDXn31VW3evFlHjhzR559/rpMnT6px48bO4+3YsUN79+7VqVOndPny5VK/JsJNORAdLX3+efZ8VFdNtQUAwA158skn5e7urqioKAUHB+vSpUtas2aNMjIydMcdd6hZs2YaM2aMgoKC5ObmpoCAAP3444/q1auXbr75Zj377LOaOnWqevbsKUl65JFHFBkZqTZt2ig4OFhr1qwp9Wti+oVy5MMPpUGDzNdvv20+Ng4AsB7TLxQPpl+ogB5+WHr5ZfP1X/5izkEFAABcEW7Kmb//XXr0UXN8qAEDpHXrrK4IAICyhXBTzjgc0owZ5uzhv/8u9ekj7dtndVUAAJQdhJtyyMNDWrBAatNGOn3aHAPnxAmrqwIAoGwg3JRTlStLS5dK9etLv/wi/fGPUlqa1VUBQMVWwZ7RKXbF9fMj3JRjISHSsmVStWrSpk3SAw9IV65YXRUAVDyVKlWSJF24YNFkmTZx6dIlSZK7u/sNHYcRisu5m2+WvvxS6trVbMkZNUqaObPAE8ICAIqBu7u7goKCdOJ/fQR8fX3l4D/iQsnMzNTJkyfl6+ub58jIBUW4sYGOHaWPPzZnEH/3XaluXQb6A4DSljUL9gk6QRaZm5ub6tSpc8PBkEH8bOTtt83xbyTpgw/McXEAAKUrIyPDkikH7MDT01Nubrn3mCnM5zctNzYyapR05Ij0+uvSsGFSzZrm7SoAQOlxd3e/4T4juDF0KLaZ117L7lh8zz3Sjh1WVwQAQOki3NiMm5s0b550221SaqrUq5eUmGh1VQAAlB7CjQ15eUmLF0tRUdLRo+Ygf2fPWl0VAAClg3BjU1WqmGPghIZKu3ZJ/fpJ6elWVwUAQMkj3NhYnTrS119L/v7SypXS0KFSZqbVVQEAULIINzbXooW0aJE5H9X8+eas4gAA2BnhpgLo3l16/33z9eTJ0jvvWFsPAAAliXBTQQweLL30kvn6L3+RvvjC2noAACgphJsKZMIE6ZFHzH43AwZI69dbXREAAMWPcFOBOBzmLalevaSLF6U+faT9+62uCgCA4kW4qWA8PKQFC6TWraVTp8wxcJjjDQBgJ4SbCsjPT/rqK6lePengQbMF58IFq6sCAKB4EG4qqJAQc5C/qlWljRuz56MCAKC8I9xUYJGR0n/+I3l7m1+feEIyDKurAgDgxhBuKriOHaWPPjI7G8+caY6DAwBAeUa4ge65R5o2zXw9frwZdgAAKK8IN5Bk3pL661/N10OHSsuXW1sPAABFRbiB05QpUv/+0uXL5iPikyYxkzgAoPwh3MDJzU3617/M21SXL0svvCC1asVIxgCA8oVwAxfe3tLCheZAf9WrSz//bHY6HjNGOn/e6uoAALg+wg1ycDjM21M//ywNGmQ+Hj59utSsmRQXZ3V1AADkj3CDPFWrZt6m+uYbqU4d6fBh6Y47zA7Hv/1mdXUAAOSOcIPr6tFD2rXLfKLK4ZDmzZOioszbVwz6BwAoawg3KBA/P/PW1Jo1UuPGUnKy9Kc/mZ2Pjx2zujoAALIRblAoMTHStm3SxInmDONLlpitOO+/TysOAKBsINyg0Ly8pBdflLZskdq2lVJSpEcekbp1M2cZBwDASoQbFFnz5tK6ddLUqZKPj/TDD+YTVVOnMsM4AMA6hBvcEHd3adw4aedO6Q9/kC5elJ580rx9tWOH1dUBACoiwg2KRYMG0vffm31vAgOlzZul1q3NvjlM4QAAKE2EGxQbh0MaPtwc/K9fP/PW1MsvSy1bSmvXWl0dAKCiINyg2NWsKX3+uTkOTkiItHu31LmzOU4OUzgAAEoa4QYl5t57zVacoUPNx8T/8Q+pSRNzxGMAAEoK4QYlqmpVac4c6bvvpPBw6cgRqWdPc86q06etrg4AYEeEG5SK7t2lhARzdnGHQ/rwQ3Ok4wULGPwPAFC8CDcoNZUrS2++aXYujoqSTp6UHnhA6ttXOnrU6uoAAHZBuEGp69BB2rpVev55qVIl6csvzbAze7aUmWl1dQCA8o5wA0t4eUmTJpkhp107KTVV+n//zxwIcP9+q6sDAJRnhBtYqmlT8zbVm29Kvr7SqlXmtA5TpjCFAwCgaAg3sJy7u9nROCHBnHzz99+lp5+W2reX4uOtrg4AUN4QblBm1KtnPjI+Z44UFGTesmrTRpowwQw8AAAUBOEGZYrDYQ76t3u3OQhgRob06qtSixbS6tVWVwcAKA8INyiTatQwp29YtMh8vXevdMst0siRZudjAADyQrhBmXbPPeYUDsOHm9+/847ZCfnrr62tCwBQdhFuUOZVqSK9/770/fdS/fpSYqLUu7f00EPSqVNWVwcAKGsINyg3unaVduyQxo2T3Nykjz4yp3CYP58pHAAA2Qg3KFcqV5amTpXWrTNvT506JT34oNSnj9miAwAA4QblUrt20pYt0osvmlM4fPWV1KSJNHMmUzgAQEVHuEG55ekpTZxoDvQXEyOdOyc9/rjUpYu0b5/V1QEArEK4QbkXFSX99JM0fbp52+qnn8wpHF57Tbp82erqAAClzdJw8+OPP6pPnz6qWbOmHA6HlixZku/2K1eulMPhyLEkJSWVTsEos9zdpSeeMKdwuOMOKT1dGj9eio6W3n5bOnvW6goBAKXF0nCTlpam6OhozZgxo1D77d27V8ePH3cu1atXL6EKUd6Eh0vffCP9619S1armSMd/+YtUs6Y58vH69TxZBQB252HlyXv27KmePXsWer/q1asrKCio+AuCLTgc0qBB0l13SR9+KL37rrRrlzRvnrk0ayb9v/8nDRxozmEFALCXctnnpkWLFgoNDVX37t21Zs0aq8tBGRUUZLba7Nxpzks1aJDk7W1+P2qU2ZozbBitOQBgN+Uq3ISGhmrWrFlatGiRFi1apLCwMHXp0kVbt27Nc5/09HSlpqa6LKhYHA6pUyfzVtWxY2bH46go6eJFae5c80mrFi2kGTOklBSrqwUA3CiHYZSN31kdDocWL16svn37Fmq/2267TXXq1NGHH36Y6/uTJk3SCy+8kGN9SkqKAgICilIqbMAwpLVrpdmzpU8/lX7/3Vzv4yM98IB526pdOzMYAQCsl5qaqsDAwAJ9fperlpvctGvXTgcOHMjz/fHjxyslJcW5JDKMLeTamnP0aM7WnA4dzNacd96hNQcAyptyH27i4+MVGhqa5/teXl4KCAhwWYCrVa2a/Rj56tXSww9LXl7mPFYjR5p9c4YPlzZsoG8OAJQHloab8+fPKz4+XvHx8ZKkQ4cOKT4+XkeOHJFktroMGjTIuf20adP0xRdf6MCBA0pISNCYMWP0ww8/aOTIkVaUD5vJas354AOzb860aebEnBcuSHPmmK05LVvSmgMAZZ2l4Wbz5s1q2bKlWrZsKUkaN26cWrZsqeeee06SdPz4cWfQkaRLly7pr3/9q5o1a6bbbrtN27dv1/fff6+uXbtaUj/sq2pVafRo8xHyn37Kbs3Zvt21NWfjRlpzAKCsKTMdiktLYTokAVf77bfscXN2785eHx1tdkB+8EEpMNC6+gDAzipUh2KgtFzbmvPQQ9mtOY8/brbmjBhBaw4AWI1wAxSSwyF17my24hw7Jr35ZnbfnH/+U2rfXmrVSpo5U2JYJQAofYQb4AZUrSqNGWO25vz4Y3ZrTny82ZoTGmq25mzaRGsOAJQWwg1QDBwO6ZZbzNaco0fN1pxGjbJbc9q1M1tzZs2iNQcAShrhBihm1aqZrTk//2y25gwcmN2a8+c/m31zHnmE1hwAKCmEG6CEZLXm/PvfZmvOG2+YrTlpadL775utOa1b05oDAMWNcAOUgmrVpLFjzdacVauyW3O2bXNtzdm82epKAaD8I9wApcjhkG691bU1JzIyuzWnbVuzNefdd6Vz56yuFgDKJ8INYJGs1pzdu83WnAcflDw9pa1bpcceM5+0evRRWnMAoLAYoRgoQ06fNmcqnz1b2rs3e32zZtKdd0rdu5tj7Pj4WFcjAFihMJ/fhBugDDIM80mr2bOlhQulS5ey3/P2NgNO9+7mEh0tudEGC8DmCDf5INygvDl9Wvr2WykuzlyOHnV9PzhY6to1O+yEhVlTJwCUJMJNPgg3KM8MQ9qzJzvorFwpnT/vuk1kZHbQ6dJF4q85ADsg3OSDcAM7uXRJ2rAhO+xs3ChlZma/7+4udeiQHXbatZM8PKyrFwCKinCTD8IN7OzsWWnFiuywc+CA6/sBAdLtt2eHnYYNzcfTAaCsI9zkg3CDiuTw4eygs3y59Ntvru/XqZMddLp2lW66yZIyAeC6CDf5INygosrIMEdEzgo7a9a4PoUlSS1bZoedzp3NJ7MAoCwg3OSDcAOY0tKkn37KDjs7d7q+7+1tzo2VFXaaN+eRcwDWIdzkg3AD5C4pSfr+++ywc/y46/vVq7s+cl67tjV1AqiYCDf5INwA12cY5iSfWUFn1SqzpedqjRq5PnLu729JqQAqCMJNPgg3QOFduiStW5cddjZvdn3k3MPD9ZHztm155BxA8SLc5INwA9y4M2ekH37IDju//OL6fmCg6yPnERE8cg7gxhBu8kG4AYrfL7+4PnJ+9qzr+3XrZj9u3rGjOUUEYQdAYRBu8kG4AUpWRoa0ZUt22Fm7Vrp82XWb0FApJsa8ldWhg9S6teTra029AMoHwk0+CDdA6Tp/3pzhPC7O/Lp9uxmArububs5ufnXgadCA1h0A2Qg3+SDcANa6cMFs2Vm3Tlq/3vyalJRzu2rVzJCTFXjatmUSUKAiI9zkg3ADlC2GISUmZged9eulrVtzjp7scEhNmrgGnkaNGFgQqCgIN/kg3ABlX3q6FB/vGnh+/TXndgEBUvv22WGnfXupatVSLxdAKSDc5INwA5RPx49LGzZkB55Nm6SLF3Nud/PNrq07TZsy5g5gB4SbfBBuAHu4csWcD2v9+uzAs39/zu18fc3+OlmBp317qUaN0q8XwI0h3OSDcAPY1+nT2a0769ebr1NTc24XHp79VFZMjNSiheTpWdrVAigMwk0+CDdAxZGRIe3Zkx121q+Xdu0yOzFfzctLatXKNfDUrs2j6EBZQrjJB+EGqNhSUsz+OlcHntOnc25Xs2Z22GGgQcB6hJt8EG4AXM0wpAMHXPvu7NiRc6BBDw9zoMGssNOpk3l7i9YdoHQQbvJBuAFwPWlp5kCDVwee3AYarFnTDDmdO5tL8+Y8mQWUFMJNPgg3AArLMKQjR7LDztq15kCDV664ble5stlfJyvwtG8v+ftbUzNgN4SbfBBuABSHCxekjRulNWuk1avNwHPtk1lubuaTWFlhp1MnqVYtS8oFyj3CTT4INwBKQkaG+STW6tXZgefIkZzbhYdnB53OnaWoKKaQAAqCcJMPwg2A0pKYaAadrLCzY4eUmem6TVCQ1LFjdthp21by8bGkXKBMI9zkg3ADwCqpqWafnayws369eXvrapUqmY+dX30rKzjYmnqBsoRwkw/CDYCy4vJlaft211tZuT2VdfPNrreyGjbkEXRUPISbfBBuAJRVhiEdOuQadn7+Oed2wcFm0MkKO61aMX0E7I9wkw/CDYDy5LffzCexssLOpk1SerrrNt7eUrt22WEnJkaqUsWaeoGSQrjJB+EGQHmWnm4OMJjVurNmTc7pIxwOqUkT11tZdetyKwvlG+EmH4QbAHZiGNLeva63sg4cyLldzZquYYfRlFHeEG7yQbgBYHfJya6PoOc2mrKfn3krq0kTs8Ny1hIWJrm7W1M3kB/CTT4INwAqmoKMppzFy8t8GuvqwJO13HQTt7ZgHcJNPgg3ACq6rNGUN26U9u3LXg4cMB9Pz0tQkBQZmTP0NGxozqsFlCTCTT4INwCQuytXzCkj9u51DT379uU+lcTVatUyg8614Sc83ByYELhRhJt8EG4AoPAuXJAOHjSDzrXh59qnta7m4SHVr5978AkN5TYXCo5wkw/CDQAUr9Onpf37s8NOVvjZv1+6eDHv/SpXzg461wafwMDSqx/lA+EmH4QbACgdmZnS0aM5b3Ht3WuOxHztJKJXq1499+DToIHZ6RkVD+EmH4QbALDepUvSL7/kDD779knHj+e9n5ubOSBhbp2aw8IYu8fOCDf5INwAQNmWmup6m+vqFp9z5/Ler1IlqV49KSIi51K3LvNvlXeEm3wQbgCgfDIMc4DC3Fp7Dh40W4PyktXik1vwqV/fnJ8LZRvhJh+EGwCwn4wMs3/PgQPZy8GD2a8vXMh7X4dDql079+DToAFj+JQVhJt8EG4AoGIxDCkpyTX4ZC379+d/q0syH1nPCjrXhh+e6io9hJt8EG4AAFkMQzp1Kvfgc/Bg/mP4SOaUFLm1+ERESFWrMo5PcSLc5INwAwAoqDNnXG9vXb0kJ+e/b1BQ7re5IiKkkBCCT2GVeLj517/+pZtuukm9e/eWJP3tb3/T7NmzFRUVpfnz56tu3bpFq7wUEG4AAMXh3Lm8g8/Ro/nvW7ly7q09UVHmGD/IqcTDTWRkpGbOnKk//OEPWrdunbp166Y333xTS5culYeHhz7//PMiF1/SCDcAgJJ24YI5UGFuwefIkesPYNismdS0qfm1WTOpSRM6Npd4uPH19dWePXtUp04dPf300zp+/Lg++OAD7dq1S126dNHJkyeLXHxJI9wAAKyUni4dPpwz9OzbZwai3D6VHQ5zDJ+ssJO1NGxYcQYuLMznd5F+JH5+fjp9+rTq1Kmj7777TuPGjZMkeXt762J+E4kAAFDBeXmZU0pERuZ8Ly1N+vlnaedOc0lIML8mJ5sjOv/yi/TFF9nbe3pKjRu7Bp6mTc1H2ytyn54ihZvu3btrxIgRatmypfbt26devXpJknbt2qXw8PDirA8AgAqjcmWpbVtzudrJk65hJ+t1Wpq0fbu5XC0oyPW2VtbroKDSuhJrFSnczJgxQ88++6wSExO1aNEiVatWTZK0ZcsWDRgwoFgLBACgogsOlv7wB3PJkplp3t66OvDs3GlOU3H2rLR6tblcrXbtnP15Gje232SkPAoOAICNpKebAefqwJOQYHZkzo27uzn56NWBp1kzs4+Pm1vp1p6fEu9Q/M0338jPz0+dO3eWZLbkvPfee4qKitKMGTNUpUqVolVeCgg3AICKKCUl522tnTvNsXxy4+trPqV1bSdmqx5VL/Fw06xZM02ePFm9evXSzp071bZtW40bN04rVqxQo0aNNHfu3CIXX9IINwAAmAxDOnYsZ+D5+WezBSg3wcE5A09UlOTnV7K1lni48fPzU0JCgsLDwzVp0iQlJCRo4cKF2rp1q3r16qWkpKQiF1/SCDcAAOTvyhXz8fRr+/McPJj7o+qSObt6Vthp1Urq1694ayrxR8E9PT114X9TrH7//fcaNGiQJKlq1apKTU0tyiEBAEAZ4eEhNWpkLvfdl70+LU3avds18OT2qHrLlsUfbgpVf1F26ty5s8aNG6dOnTpp48aNWrBggSRp3759ql27drEWCAAAyobKlaU2bczlaidPurbyWD0LU5H6Qb/99tvy8PDQwoULNXPmTNWqVUuStGzZMt15550FPs6PP/6oPn36qGbNmnI4HFqyZMl191m5cqVatWolLy8vRUREaN68eUW5BAAAUEyCg6Xbb5eeeEJ67z3p2WetradILTd16tTR0qVLc6x/8803C3WctLQ0RUdHa9iwYbrnnnuuu/2hQ4fUu3dvPfbYY/roo4+0fPlyjRgxQqGhoerRo0ehzg0AAOypyDNSZGRkaMmSJdq9e7ckqUmTJrrrrrvk7u5e4GP07NlTPXv2LPD2s2bNUr169TR16lRJUuPGjbV69Wq9+eabhBsAACCpiOHmwIED6tWrl44eParI/02OERsbq7CwMH311Vdq0KBBsRaZJWsG8qv16NFDY8aMyXOf9PR0pV/1PBsdngEAsLci9bl54okn1KBBAyUmJmrr1q3aunWrjhw5onr16umJJ54o7hqdkpKSFBIS4rIuJCREqampeU7YGRsbq8DAQOcSFhZWYvUBAADrFSncrFq1SlOmTFHVqlWd66pVq6bXXntNq1atKrbiisP48eOVkpLiXBITE60uCQAAlKAi3Zby8vLSuXPncqw/f/68PD09b7iovNSoUUPJycku65KTkxUQECAfH59c9/Hy8pKX3WYEAwAAeSpSy80f//hHPfroo9qwYYMMw5BhGFq/fr0ee+wx3XXXXcVdo1NMTIyWL1/usi4uLk4xMTEldk4AAFC+FCncvPXWW2rQoIFiYmLk7e0tb29vdezYUREREZo2bVqBj3P+/HnFx8crPj5ekvmod3x8vI78b+rS8ePHO0c/lqTHHntMv/zyi/72t79pz549euedd/Tpp59q7NixRbkMAABgQ0WaWyrLgQMHnI+CN27cWBEREYXaf+XKlbr99ttzrB88eLDmzZunIUOG6PDhw1q5cqXLPmPHjtXPP/+s2rVra+LEiRoyZEiBz8ncUgAAlD8lMnHmuHHjClzAG2+8UeBtSxvhBgCA8qdEJs7ctm1bgbZzOBwFPSQAAECxK3C4WbFiRUnWAQAAUCyK1KEYAACgrCLcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWykT4WbGjBkKDw+Xt7e32rdvr40bN+a57bx58+RwOFwWb2/vUqwWAACUZZaHmwULFmjcuHF6/vnntXXrVkVHR6tHjx46ceJEnvsEBATo+PHjzuXXX38txYoBAEBZZnm4eeONN/TII49o6NChioqK0qxZs+Tr66s5c+bkuY/D4VCNGjWcS0hISClWDAAAyjJLw82lS5e0ZcsWdevWzbnOzc1N3bp107p16/Lc7/z586pbt67CwsJ09913a9euXXlum56ertTUVJcFAADYl6Xh5tSpU8rIyMjR8hISEqKkpKRc94mMjNScOXP0xRdf6N///rcyMzPVsWNH/fe//811+9jYWAUGBjqXsLCwYr8OAABQdlh+W6qwYmJiNGjQILVo0UK33XabPv/8cwUHB+vdd9/Ndfvx48crJSXFuSQmJpZyxQAAoDR5WHnym266Se7u7kpOTnZZn5ycrBo1ahToGJUqVVLLli114MCBXN/38vKSl5fXDdcKAADKB0tbbjw9PdW6dWstX77cuS4zM1PLly9XTExMgY6RkZGhnTt3KjQ0tKTKBAAA5YilLTeSNG7cOA0ePFht2rRRu3btNG3aNKWlpWno0KGSpEGDBqlWrVqKjY2VJL344ovq0KGDIiIidPbsWb3++uv69ddfNWLECCsvAwAAlBGWh5v7779fJ0+e1HPPPaekpCS1aNFC33zzjbOT8ZEjR+Tmlt3AdObMGT3yyCNKSkpSlSpV1Lp1a61du1ZRUVFWXQIAAChDHIZhGFYXUZpSU1MVGBiolJQUBQQEWF0OAAAogMJ8fpe7p6UAAADyQ7gBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2UibCzYwZMxQeHi5vb2+1b99eGzduzHf7zz77TI0aNZK3t7eaNWumr7/+upQqBQAAZZ3l4WbBggUaN26cnn/+eW3dulXR0dHq0aOHTpw4kev2a9eu1YABAzR8+HBt27ZNffv2Vd++fZWQkFDKlQMAgLLIYRiGYWUB7du3V9u2bfX2229LkjIzMxUWFqa//OUveuaZZ3Jsf//99ystLU1Lly51ruvQoYNatGihWbNmXfd8qampCgwMVEpKigICAorvQn7bIq3oKTncJYfb/77m8VrXef/abd3cS3i/3PaXZBiSMs2vRqakEvp69Xmu+7UI5yhppf1PyOHIenHN1yK+57hqmyK9V5hzOHL5d3D116K+97+vJfGe85zX1HL1dZeY0jiHlP3v5H9fjdy+v842xbk+1/NfZ18jU+b/Exn/+38la8n43/qr3lOmlJnHepf9r15/o/tftT6//eW45u/ltX/vrvN9jr+z1/49z+f7Yju+m1QpSKrSXMWpMJ/fHsV65kK6dOmStmzZovHjxzvXubm5qVu3blq3bl2u+6xbt07jxo1zWdejRw8tWbKkJEu9vox0Kf2ktTUAAFAW3BQj3bHWstNbGm5OnTqljIwMhYSEuKwPCQnRnj17ct0nKSkp1+2TkpJy3T49PV3p6enO71NTU2+w6jxUaSH12nlVCs9wfa081hfkdda+mYU8TtZvB0U5v5T922lBvjocMlP79b4WZZ8C1pDrV4dK77ff0pDXb7LXee+6v/kW9b2CnP/qOnL7jTqX33QL9V5GPsfM7TftXN7Lcaxrz5XbfiWtNFoEDem6LXJXr7/OtgVpuSuuc127PtdWuHxa3nJbn9XinWsLxzX7FnZ9gWpwKLul/DqtRzn+fl6npSnfFq3rHSu/Vqc89vUNk5UsDTelITY2Vi+88ELJn8jDVwpqWvLnAQAA+XKz8uQ33XST3N3dlZyc7LI+OTlZNWrUyHWfGjVqFGr78ePHKyUlxbkkJiYWT/EAAKBMsjTceHp6qnXr1lq+fLlzXWZmppYvX66YmJhc94mJiXHZXpLi4uLy3N7Ly0sBAQEuCwAAsC/Lb0uNGzdOgwcPVps2bdSuXTtNmzZNaWlpGjp0qCRp0KBBqlWrlmJjYyVJo0eP1m233aapU6eqd+/e+uSTT7R582bNnj3byssAAABlhOXh5v7779fJkyf13HPPKSkpSS1atNA333zj7DR85MgRubllNzB17NhRH3/8sZ599ln9/e9/V8OGDbVkyRI1bUp/FwAAIOvHuSltJTbODQAAKDGF+fy2tM8NAABAcSPcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAWyHcAAAAW7F8+oXSljUgc2pqqsWVAACAgsr63C7IxAoVLtycO3dOkhQWFmZxJQAAoLDOnTunwMDAfLepcHNLZWZm6tixY/L395fD4SjWY6empiosLEyJiYnlet4qrqNs4TrKFq6j7LHLtXAd+TMMQ+fOnVPNmjVdJtTOTYVruXFzc1Pt2rVL9BwBAQHl+i9mFq6jbOE6yhauo+yxy7VwHXm7XotNFjoUAwAAWyHcAAAAWyHcFCMvLy89//zz8vLysrqUG8J1lC1cR9nCdZQ9drkWrqP4VLgOxQAAwN5ouQEAALZCuAEAALZCuAEAALZCuAEAALZCuCkGP/74o/r06aOaNWvK4XBoyZIlVpdUJLGxsWrbtq38/f1VvXp19e3bV3v37rW6rEKbOXOmmjdv7hxAKiYmRsuWLbO6rBvy2muvyeFwaMyYMVaXUmiTJk2Sw+FwWRo1amR1WUVy9OhRPfTQQ6pWrZp8fHzUrFkzbd682eqyCiU8PDzHn4fD4dDIkSOtLq1QMjIyNHHiRNWrV08+Pj5q0KCBXnrppQLNO1TWnDt3TmPGjFHdunXl4+Ojjh07atOmTVaXla/rfe4ZhqHnnntOoaGh8vHxUbdu3bR///5Sq49wUwzS0tIUHR2tGTNmWF3KDVm1apVGjhyp9evXKy4uTpcvX9Ydd9yhtLQ0q0srlNq1a+u1117Tli1btHnzZv3hD3/Q3XffrV27dlldWpFs2rRJ7777rpo3b251KUXWpEkTHT9+3LmsXr3a6pIK7cyZM+rUqZMqVaqkZcuW6eeff9bUqVNVpUoVq0srlE2bNrn8WcTFxUmS/vSnP1lcWeFMnjxZM2fO1Ntvv63du3dr8uTJmjJliv7xj39YXVqhjRgxQnFxcfrwww+1c+dO3XHHHerWrZuOHj1qdWl5ut7n3pQpU/TWW29p1qxZ2rBhgypXrqwePXro999/L50CDRQrScbixYutLqNYnDhxwpBkrFq1yupSbliVKlWM999/3+oyCu3cuXNGw4YNjbi4OOO2224zRo8ebXVJhfb8888b0dHRVpdxw55++mmjc+fOVpdR7EaPHm00aNDAyMzMtLqUQundu7cxbNgwl3X33HOPMXDgQIsqKpoLFy4Y7u7uxtKlS13Wt2rVypgwYYJFVRXOtZ97mZmZRo0aNYzXX3/due7s2bOGl5eXMX/+/FKpiZYb5CklJUWSVLVqVYsrKbqMjAx98sknSktLU0xMjNXlFNrIkSPVu3dvdevWzepSbsj+/ftVs2ZN1a9fXwMHDtSRI0esLqnQvvzyS7Vp00Z/+tOfVL16dbVs2VLvvfee1WXdkEuXLunf//63hg0bVuwTCZe0jh07avny5dq3b58kafv27Vq9erV69uxpcWWFc+XKFWVkZMjb29tlvY+PT7ls4ZSkQ4cOKSkpyeX/rcDAQLVv317r1q0rlRoq3MSZKJjMzEyNGTNGnTp1UtOmTa0up9B27typmJgY/f777/Lz89PixYsVFRVldVmF8sknn2jr1q1l/t779bRv317z5s1TZGSkjh8/rhdeeEG33HKLEhIS5O/vb3V5BfbLL79o5syZGjdunP7+979r06ZNeuKJJ+Tp6anBgwdbXV6RLFmyRGfPntWQIUOsLqXQnnnmGaWmpqpRo0Zyd3dXRkaGXnnlFQ0cONDq0grF399fMTExeumll9S4cWOFhIRo/vz5WrdunSIiIqwur0iSkpIkSSEhIS7rQ0JCnO+VNMINcjVy5EglJCSU298cIiMjFR8fr5SUFC1cuFCDBw/WqlWryk3ASUxM1OjRoxUXF5fjN7ry5urfpJs3b6727durbt26+vTTTzV8+HALKyuczMxMtWnTRq+++qokqWXLlkpISNCsWbPKbbj55z//qZ49e6pmzZpWl1Jon376qT766CN9/PHHatKkieLj4zVmzBjVrFmz3P15fPjhhxo2bJhq1aold3d3tWrVSgMGDNCWLVusLq3c4rYUchg1apSWLl2qFStWqHbt2laXUySenp6KiIhQ69atFRsbq+joaE2fPt3qsgpsy5YtOnHihFq1aiUPDw95eHho1apVeuutt+Th4aGMjAyrSyyyoKAg3XzzzTpw4IDVpRRKaGhojnDcuHHjcnmLTZJ+/fVXff/99xoxYoTVpRTJU089pWeeeUYPPPCAmjVrpocfflhjx45VbGys1aUVWoMGDbRq1SqdP39eiYmJ2rhxoy5fvqz69etbXVqR1KhRQ5KUnJzssj45Odn5Xkkj3MDJMAyNGjVKixcv1g8//KB69epZXVKxyczMVHp6utVlFFjXrl21c+dOxcfHO5c2bdpo4MCBio+Pl7u7u9UlFtn58+d18OBBhYaGWl1KoXTq1CnH0Aj79u1T3bp1LaroxsydO1fVq1dX7969rS6lSC5cuCA3N9ePMHd3d2VmZlpU0Y2rXLmyQkNDdebMGX377be6++67rS6pSOrVq6caNWpo+fLlznWpqanasGFDqfV95LZUMTh//rzLb6GHDh1SfHy8qlatqjp16lhYWeGMHDlSH3/8sb744gv5+/s7740GBgbKx8fH4uoKbvz48erZs6fq1Kmjc+fO6eOPP9bKlSv17bffWl1agfn7++fo61S5cmVVq1at3PWBevLJJ9WnTx/VrVtXx44d0/PPPy93d3cNGDDA6tIKZezYserYsaNeffVV9e/fXxs3btTs2bM1e/Zsq0srtMzMTM2dO1eDBw+Wh0f5/Bjo06ePXnnlFdWpU0dNmjTRtm3b9MYbb2jYsGFWl1Zo3377rQzDUGRkpA4cOKCnnnpKjRo10tChQ60uLU/X+9wbM2aMXn75ZTVs2FD16tXTxIkTVbNmTfXt27d0CiyVZ7JsbsWKFYakHMvgwYOtLq1QcrsGScbcuXOtLq1Qhg0bZtStW9fw9PQ0goODja5duxrfffed1WXdsPL6KPj9999vhIaGGp6enkatWrWM+++/3zhw4IDVZRXJf/7zH6Np06aGl5eX0ahRI2P27NlWl1Qk3377rSHJ2Lt3r9WlFFlqaqoxevRoo06dOoa3t7dRv359Y8KECUZ6errVpRXaggULjPr16xuenp5GjRo1jJEjRxpnz561uqx8Xe9zLzMz05g4caIREhJieHl5GV27di3Vv28OwyiHwzkCAADkgT43AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3AADAVgg3ACqclStXyuFw6OzZs1aXAqAEEG4AAICtEG4AAICtEG4AlLrMzEzFxsaqXr168vHxUXR0tBYuXCgp+5bRV199pebNm8vb21sdOnRQQkKCyzEWLVqkJk2ayMvLS+Hh4Zo6darL++np6Xr66acVFhYmLy8vRURE6J///KfLNlu2bFGbNm3k6+urjh07usz6vX37dt1+++3y9/dXQECAWrdurc2bN5fQTwRAcSLcACh1sbGx+uCDDzRr1izt2rVLY8eO1UMPPaRVq1Y5t3nqqac0depUbdq0ScHBwerTp48uX74syQwl/fv31wMPPKCdO3dq0qRJmjhxoubNm+fcf9CgQZo/f77eeust7d69W++++678/Pxc6pgwYYKmTp2qzZs3y8PDw2VG6YEDB6p27dratGmTtmzZomeeeUaVKlUq2R8MgOJRalN0AoBhGL///rvh6+trrF271mX98OHDjQEDBjhnG/7kk0+c750+fdrw8fExFixYYBiGYTz44ING9+7dXfZ/6qmnjKioKMMwDGPv3r2GJCMuLi7XGrLO8f333zvXffXVV4Yk4+LFi4ZhGIa/v78xb968G79gAKWOlhsAperAgQO6cOGCunfvLj8/P+fywQcf6ODBg87tYmJinK+rVq2qyMhI7d69W5K0e/duderUyeW4nTp10v79+5WRkaH4+Hi5u7vrtttuy7eW5s2bO1+HhoZKkk6cOCFJGjdunEaMGKFu3brptddec6kNQNlGuAFQqs6fPy9J+uqrrxQfH+9cfv75Z2e/mxvl4+NToO2uvs3kcDgkmf2BJGnSpEnatWuXevfurR9++EFRUVFavHhxsdQHoGQRbgCUqqioKHl5eenIkSOKiIhwWcLCwpzbrV+/3vn6zJkz2rdvnxo3bixJaty4sdasWeNy3DVr1ujmm2+Wu7u7mjVrpszMTJc+PEVx8803a+zYsfruu+90zz33aO7cuTd0PAClw8PqAgBULP7+/nryySc1duxYZWZmqnPnzkpJSdGaNWsUEBCgunXrSpJefPFFVatWTSEhIZowYYJuuukm9e3bV5L017/+VW3bttVLL72k+++/X+vWrdPbb7+td955R5IUHh6uwYMHa9iwYXrrrbcUHR2tX3/9VSdOnFD//v2vW+PFixf11FNP6b777lO9evX03//+V5s2bdK9995bYj8XAMXI6k4/ACqezMxMY9q0aUZkZKRRqVIlIzg42OjRo4exatUqZ2ff//znP0aTJk0MT09Po127dsb27dtdjrFw4UIjKirKqFSpklGnTh3j9ddfd3n/4sWLxtixY43Q0FDD09PTiIiIMObMmWMYRnaH4jNnzji337ZtmyHJOHTokJGenm488MADRlhYmOHp6WnUrFnTGDVqlLOzMYCyzWEYhmFxvgIAp5UrV+r222/XmTNnFBQUZHU5AMoh+twAAABbIdwAAABb4bYUAACwFVpuAACArRBuAACArRBuAACArRBuAACArRBuAACArRBuAACArRBuAACArRBuAACArRBuAACArfx/BWiQW06gQxoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(range(epochs)) + 1), train_losses, label='train', color='blue')\n",
    "plt.plot(range(1, len(range(epochs)) + 1), test_losses, label='test', color='orange')\n",
    "plt.legend()\n",
    "plt.title('Loss for epoch')\n",
    "plt.xticks(range(1, epochs + 1))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
