{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.datasets import make_classification, make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both regression and classification RandomForest model (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_ensembles=100, learner_type='classification'):\n",
    "        self.n_ensembles = n_ensembles\n",
    "        self.weak_learner = None\n",
    "        self.learner_type = learner_type\n",
    "        self.feature_size = 0\n",
    "        self.models = []\n",
    "        self.set_weak_learner()\n",
    "\n",
    "    def set_weak_learner(self):\n",
    "        if self.learner_type == 'classification':\n",
    "            self.weak_learner = DecisionTreeClassifier\n",
    "        elif self.learner_type == 'regression':\n",
    "            self.weak_learner = DecisionTreeRegressor\n",
    "        else:\n",
    "            raise ValueError('Invalid learner type, use \"classification\" or \"regression\"')\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n_samples, n_features = X.shape\n",
    "        if self.learner_type == 'classification':\n",
    "            self.feature_size = np.floor(np.sqrt(n_features)).astype(int)\n",
    "        elif self.learner_type == 'regression':\n",
    "            self.feature_size = max(1, n_features // 3)\n",
    "\n",
    "        # Should be better with multi thread\n",
    "        for _ in range(self.n_ensembles):\n",
    "            random_features = np.random.choice(n_features, size=self.feature_size, replace=False)\n",
    "            bootstrapped_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_data, y_data = X[bootstrapped_indices, :][:, random_features], y[bootstrapped_indices]\n",
    "\n",
    "            model = self.weak_learner()\n",
    "            model.fit(X_data, y_data)\n",
    "            self.models.append((model, random_features))\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        weak_predicts = []\n",
    "        for model, features in self.models:\n",
    "            weak_predicts.append(model.predict(X[:, features]))\n",
    "\n",
    "        predicits = np.array(weak_predicts)\n",
    "        if self.learner_type == 'classification':\n",
    "            return mode(predicits, axis=0).mode[0]\n",
    "        return np.mean(predicits, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boostings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, model_type='tree', n_estimators=100):\n",
    "        self.model_type = model_type\n",
    "        self.model = None\n",
    "        self.n_estimators = n_estimators\n",
    "        self.weights = None\n",
    "        self.models = []\n",
    "        self.alphas = []\n",
    "        self.set_model()\n",
    "\n",
    "    def set_model(self):\n",
    "        if self.model_type == 'tree':\n",
    "            self.model = DecisionTreeClassifier\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n_samples = X.shape[0]\n",
    "        self.weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            model = self.model()\n",
    "            model.fit(X, y, sample_weight=self.weights)\n",
    "\n",
    "            y_hat = model.predict(X)\n",
    "\n",
    "            j_w = np.sum(self.weights * (y_hat != y))\n",
    "            error_m = j_w\n",
    "\n",
    "            alpha = 0.5 * np.log((1 - error_m) / max(error_m, 1e-10))\n",
    "\n",
    "            self.weights = self.weights * np.exp(-alpha * y_hat * y)\n",
    "\n",
    "            self.weights /= np.sum(self.weights)\n",
    "\n",
    "            self.models.append(model)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        predicts = np.array([model.predict(X) for model in self.models])\n",
    "        return np.sign(np.array(self.alphas) @ predicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
